{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ask a home buyer to describe their dream house, and they probably won’t begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition’s dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
    "The potential for creative feature engineering provides a rich opportunity for fun and learning. This dataset lends itself to advanced regression techniques like random forests and gradient boosting with the popular XGBoost library.\n",
    "\n",
    "https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading & Preparation\n",
    "## Load up Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pandas.api.types import CategoricalDtype\n",
    "import math\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Plotting stuff\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Stats and ML libraries\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Pandas display formatting - to show more columns\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load training data\n",
    "# na_filter - Pandas impute NA as missing, but here it means either \"No\" for cateoricals or missing for numerics, so we have to handle this manually\n",
    "house_train = pd.read_csv(Path('data/train.csv'), na_filter=False)\n",
    "house_test = pd.read_csv(Path('data/test.csv'), na_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training shape: {house_train.shape}\")\n",
    "print(f\"Testing shape: {house_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "Pandas guesses the types of all the columns when it scans a csv. It does a reasonable job most of the time, but we need to check carefully.\n",
    "\n",
    "### Build a categorical data reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive categorical features and all their possible categories from data_description.txt\n",
    "categorical_lookup = {}\n",
    "with open(Path('data/data_description.txt'), \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        if (not re.search(r\"^\\s\", line)) & (\": \" in line):\n",
    "            # if line doesnt start with space/tab, and contains :, its a key\n",
    "            col, _ = line.strip().split(\":\")\n",
    "            categorical_lookup[col] = []\n",
    "        else:\n",
    "            # else if its longer than zero it's a value\n",
    "            if len(line.strip()) > 0:\n",
    "                val = line.strip().split(\"\\t\")[0].strip()\n",
    "                categorical_lookup[col].append(val)\n",
    "                \n",
    "# Print some formatted results\n",
    "categorical_lookup = {k:categorical_lookup[k] for k in list(categorical_lookup.keys()) if len(categorical_lookup[k]) > 0}\n",
    "for key in categorical_lookup.keys():\n",
    "    print(f\"{key}: {categorical_lookup[key][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like thse contain ordinal and nominal variables as well some that could be converted to numerics (OverallQual, OverallCond)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other columns contain values missing from the lookup (MSSubClass, MSZoning, Neighborhood, BldgType, Exterior2nd, SaleType).\n",
    "\n",
    "We need to look at these individually to understand them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Categories and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the values in the category lookup match those in the data\n",
    "def test_missing_categories():\n",
    "    missing_categories = {}\n",
    "    for col in categorical_lookup.keys():\n",
    "        cat_diff = list(set(house_train[col].dropna().unique()) - set(categorical_lookup[col]))\n",
    "        \n",
    "        # level_diff = list(set([str(i) for i in house_train[varname] if str(i) != \"nan\"]) - set(categorical_lookup[varname]))\n",
    "        if len(cat_diff) > 0:\n",
    "            missing_categories[col] = cat_diff\n",
    "    return(missing_categories)\n",
    "\n",
    "pprint.pprint(test_missing_categories())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we saw that certain of the values that occur in the data set, are missing from the categorical lookup, lets fix them.\n",
    "\n",
    "We can automate a lot of things, but some things need to be done manually, especially during EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remainder of the categorical errors appear to be typos in the lookup, so lets update the lookup\n",
    "# small helper to replace values in the category lookup\n",
    "def cat_val_replacer(colname, old, new):\n",
    "    try:\n",
    "        idx = categorical_lookup[colname].index(old)\n",
    "        categorical_lookup[colname][idx] = new\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSZoning\n",
    "print(test_missing_categories()[\"MSZoning\"])\n",
    "# print(house_train[\"MSZoning\"].unique())\n",
    "# print(house_test[\"MSZoning\"].unique())\n",
    "print(categorical_lookup[\"MSZoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_val_replacer(\"MSZoning\", 'C', 'C (all)')\n",
    "print(categorical_lookup[\"MSZoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood\n",
    "print(test_missing_categories()[\"Neighborhood\"])\n",
    "# print(house_train[\"Neighborhood\"].unique())\n",
    "# print(house_test[\"Neighborhood\"].unique())\n",
    "print(categorical_lookup[\"Neighborhood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_val_replacer(\"Neighborhood\", 'Names', 'NAmes')\n",
    "print(categorical_lookup[\"Neighborhood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BldgType\n",
    "print(test_missing_categories()[\"BldgType\"])\n",
    "print(house_train[\"BldgType\"].unique())\n",
    "print(house_test[\"BldgType\"].unique())\n",
    "print(categorical_lookup[\"BldgType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_val_replacer(\"BldgType\", '2FmCon', '2fmCon')\n",
    "cat_val_replacer(\"BldgType\", 'Duplx', 'Duplex')\n",
    "cat_val_replacer(\"BldgType\", 'TwnhsI', 'Twnhs')\n",
    "print(categorical_lookup[\"Neighborhood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exterior2nd\n",
    "print(test_missing_categories()[\"Exterior2nd\"])\n",
    "# print(house_train[\"Exterior2nd\"].unique())\n",
    "# print(house_test[\"Exterior2nd\"].unique())\n",
    "print(categorical_lookup[\"Exterior2nd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_val_replacer(\"Exterior2nd\", 'WdShing', 'Wd Shng')\n",
    "cat_val_replacer(\"Exterior2nd\", 'CemntBd', 'CmentBd')\n",
    "cat_val_replacer(\"Exterior2nd\", 'BrkComm', 'Brk Cmn')\n",
    "print(categorical_lookup[\"Exterior2nd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSSubClass\n",
    "print(test_missing_categories()[\"MSSubClass\"])\n",
    "print(categorical_lookup[\"MSSubClass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSSubClass needs to be converted to string - why not numeric?\n",
    "house_train[\"MSSubClass\"] = house_train[\"MSSubClass\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again\n",
    "test_missing_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the NA values in Electrical and MasVnrType are different, they represent missing data\n",
    "# replace these values in the data set.\n",
    "house_train[\"MasVnrType\"] = house_train[\"MasVnrType\"].replace('NA', None)\n",
    "house_test[\"MasVnrType\"] = house_test[\"MasVnrType\"].replace('NA', None)\n",
    "house_train[\"Electrical\"] = house_train[\"Electrical\"].replace('NA', None)\n",
    "house_test[\"Electrical\"] = house_test[\"Electrical\"].replace('NA', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverallCond and OverallQual look like they should be left as numerics since theyre numeric ordinal, with equal spacing, so drop them from the category lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del categorical_lookup[\"OverallCond\"]\n",
    "del categorical_lookup[\"OverallQual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of last things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the bool column to 1/0\n",
    "house_train[\"CentralAir\"] = house_train[\"CentralAir\"].apply(lambda x: 1 if x == \"Y\" else 0)\n",
    "house_test[\"CentralAir\"] = house_test[\"CentralAir\"].apply(lambda x: 1 if x == \"Y\" else 0)\n",
    "del categorical_lookup[\"CentralAir\"]\n",
    "# house_train[\"CentralAir\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split categorical into ordinal & nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take another look at our categoricals...\n",
    "for key in categorical_lookup.keys():\n",
    "    print(f\"{key}: {categorical_lookup[key][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through these, it looks like ordinas would be the following variables, with their categories ordered as follows. These sorts of things you need to do manually..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual build ordinal lookup\n",
    "ordinal_lu = {\n",
    "    \"LotShape\": ['Reg', 'IR1', 'IR2', 'IR3'],\n",
    "    \"Utilities\": ['ELO', 'NoSeWa', 'NoSewr', 'AllPub'],\n",
    "    \"LandSlope\": ['Gtl', 'Mod', 'Sev'],\n",
    "    \"ExterQual\": ['Po','Fa', 'TA', 'Gd', 'Ex'],\n",
    "    \"ExterCond\": ['Po','Fa', 'TA', 'Gd', 'Ex'],\n",
    "    \"BsmtQual\": ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    \"BsmtCond\": ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    \"BsmtExposure\": ['NA', 'No', 'Mn', 'Av', 'Gd'],\n",
    "    \"BsmtFinType1\": ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    \"BsmtFinType2\": ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    \"HeatingQC\": ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    \"KitchenQual\": ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    \"Functional\": ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],\n",
    "    \"FireplaceQu\": ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    \"GarageFinish\": ['NA', 'Unf', 'RFn', 'Fin'],\n",
    "    \"GarageQual\": ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    \"GarageCond\": ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    \"PavedDrive\": ['N', 'P', 'Y'],\n",
    "    \"PoolQC\": ['NA', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "}\n",
    "\n",
    "non_nom = list(ordinal_lu.keys())\n",
    "nominal_lu = {k: categorical_lookup[k] for k in categorical_lookup if k not in non_nom}\n",
    "\n",
    "non_num = list(ordinal_lu.keys()) + list(nominal_lu.keys()) + [\"Id\"]\n",
    "numerics = [c for c in house_train.columns if c not in non_num]\n",
    "\n",
    "print(\"nominals\")\n",
    "for key in nominal_lu.keys():\n",
    "    print(f\"{key}: {nominal_lu[key][:5]}\")\n",
    "\n",
    "print(\"\\nordinals\")\n",
    "for key in ordinal_lu.keys():\n",
    "    print(f\"{key}: {ordinal_lu[key][:5]}\")\n",
    "\n",
    "print(\"\\nnumerics\")\n",
    "print(numerics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting column data types\n",
    "convert the data types:\n",
    "- Categorical to ordinal, nominal or boolean\n",
    "- Make sure the rest are numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_typer(pdf:pd.DataFrame):\n",
    "    for colname in pdf.columns:\n",
    "        if colname in ordinal_lu.keys():\n",
    "            cat_def = CategoricalDtype(categories=ordinal_lu[colname], ordered=True)\n",
    "            pdf[colname] = pdf[colname].astype(str).astype(cat_def)\n",
    "\n",
    "        elif colname in nominal_lu.keys():\n",
    "            cat_def = CategoricalDtype(categories=nominal_lu[colname], ordered=False)\n",
    "            pdf[colname] = pdf[colname].astype(str).astype(cat_def)\n",
    "\n",
    "        elif colname in numerics:\n",
    "            # coerce will convert \"NA\" to Nan\n",
    "            pdf[colname] = pd.to_numeric(pdf[colname], errors='coerce')\n",
    "\n",
    "    pdf[\"Id\"] = pdf[\"Id\"].astype(int)\n",
    "    return(pdf)\n",
    "\n",
    "house_train = column_typer(house_train.copy())\n",
    "house_test = column_typer(house_test.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data\n",
    "Its a good idea to save your data from time to time, so that you can more easily pick up where you left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train.to_pickle(Path(\"house_train_tidy.pkl\"))\n",
    "house_test.to_pickle(Path(\"house_test_tidy.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train = pd.read_pickle(Path(\"house_train_tidy.pkl\"))\n",
    "house_test = pd.read_pickle(Path(\"house_test_tidy.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations\n",
    "## Distributions\n",
    "### SalePrice Probability Plot\n",
    "Probability plot, a graphical method for comparing sample data against the quantiles of a specified theoretical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(house_train['SalePrice'], dist='norm', plot=plt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(np.log(house_train['SalePrice']), dist='norm', plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SalePrice\n",
    "# Take a look at the distribution of the target variable\n",
    "fig,ax = plt.subplots(1,2, sharex=False)\n",
    "house_train[\"SalePrice\"].plot(kind=\"hist\", ax=ax[0], color='tab:blue', title=\"SalePrice\", bins=20)\n",
    "np.log(house_train[\"SalePrice\"]).plot(kind=\"hist\", ax=ax[1], color='tab:orange', title=\"log(SalePrice)\", bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distributions of all numeric data\n",
    "house_train[numerics].hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand features in terms of SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_plotter(pdf:pd.DataFrame, x_vars:list, y_var:str, col_wrap:int=4):\n",
    "    g = sns.FacetGrid(pd.DataFrame(x_vars), col=0, col_wrap=col_wrap, sharex=False)\n",
    "    for ax, x_var in zip(g.axes, x_vars):\n",
    "        sns.boxplot(data=pdf, x=x_var, y=y_var, ax=ax)\n",
    "    g.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at Ordinals in terms of sames price\n",
    "facet_plotter(house_train, ordinal_lu.keys(), \"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominals\n",
    "facet_plotter(house_train, nominal_lu.keys(), \"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric variables\n",
    "f = pd.melt(house_train, id_vars=['SalePrice'], value_vars=numerics)\n",
    "sns.lmplot(\n",
    "    data=f, x=\"value\", y='SalePrice', col=\"variable\", lowess=True, \n",
    "    col_wrap=4, height=3, aspect=1,scatter_kws={'alpha':0.3, \"linewidth\":0}, line_kws={\"color\": \"C1\"}, facet_kws={\"sharex\": False});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "### Correlations between Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = house_train[numerics].corr(method='spearman')\n",
    "plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corrmat, annot=False, cmap=\"YlGnBu\", square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between Ordinal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary datframe containing the ordinal order values\n",
    "pdf_tmp = house_train[ordinal_lu.keys()].copy()\n",
    "for c in ordinal_lu.keys():\n",
    "    pdf_tmp[c] = pdf_tmp[c].cat.codes\n",
    "corrmat = pdf_tmp.corr(method='kendall')\n",
    "plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corrmat, annot=False, cmap=\"YlGnBu\", square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations with SalePrice\n",
    "### Ordinals with SalePrice\n",
    "Spearmans Rank Correlation, good for continuous and ordinal, robust to outliers, but **assumes linearity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate correlations between features and SalePrice\n",
    "def spearman_categoricals(pdf, features):\n",
    "    spr = pd.DataFrame()\n",
    "    spr['feature'] = features\n",
    "    spr['spearman'] = [pdf[f].cat.codes.corr(pdf['SalePrice'], 'spearman') for f in features]\n",
    "    spr = spr.sort_values('spearman')\n",
    "    plt.figure(figsize=(6, 0.25*len(features)))\n",
    "    sns.barplot(data=spr, y='feature', x='spearman', orient='h')\n",
    "spearman_categoricals(house_train, ordinal_lu.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerics with SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate correlations between features and SalePrice\n",
    "def spearman_numerics(pdf, features):\n",
    "    spr = pd.DataFrame()\n",
    "    spr['feature'] = features\n",
    "    spr['spearman'] = [pdf[f].corr(pdf['SalePrice'], 'spearman') for f in features]\n",
    "    spr = spr.sort_values('spearman')\n",
    "    plt.figure(figsize=(6, 0.25*len(features)))\n",
    "    sns.barplot(data=spr, y='feature', x='spearman', orient='h')\n",
    "spearman_numerics(house_train, numerics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "## Understanding missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train = pd.read_pickle(Path(\"house_train_tidy.pkl\"))\n",
    "house_test = pd.read_pickle(Path(\"house_test_tidy.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_plotter(pdf):\n",
    "    total = pdf.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (pdf.isnull().sum()/pdf.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, round(percent*100,2)], axis=1, keys=['Total', 'Percent'])\n",
    "    missing_data = missing_data[missing_data.Total>=1]\n",
    "    if len(missing_data) > 0:\n",
    "        missing_data.plot.bar(subplots=True); # Pandas\n",
    "    else:\n",
    "        print(\"No missing data\")\n",
    "    return(missing_data)\n",
    "missing_plotter(house_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_plotter(house_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with some missing data\n",
    "GarageYrBlt - numeric, we will impute that a little later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LotFrontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf=house_train.copy()\n",
    "pdf[\"frontage\"] = pdf[\"LotFrontage\"].apply(lambda x: 1 if x>0 else x)\n",
    "pdf.groupby([\"LotConfig\", \"frontage\"], dropna=False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing data across all config sizes. We will impute this below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Pattern of GarageYrBlt and some feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does GarageYrBlt relate to YearBuilt?\n",
    "plt_data = house_train[[\"YearBuilt\", \"GarageYrBlt\"]].copy()\n",
    "plt_data[\"GarageYrBlt_nafill\"] = plt_data[\"GarageYrBlt\"].fillna(plt_data[\"YearBuilt\"])\n",
    "plt_data[\"missing\"] = plt_data[\"GarageYrBlt\"].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "\n",
    "sns.scatterplot(data=plt_data, x=\"YearBuilt\", y=\"GarageYrBlt_nafill\", hue=\"missing\");\n",
    "# Looks like, in most cases, garages are built when the houses are built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming GarageYrBlt\n",
    "\n",
    "- What does missing data here mean? likely that there is no garage\n",
    "- We will try and capture the information in GarageYrBlt in 2 other variables\n",
    "    - **hasGarage**: indicates whether there is a garage or not\n",
    "    - **GarageBlt**: years + 1 after construction that the garage was built. \n",
    "        - 0 indicates no garage, + integer indicates garage built after years + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new feature: hasGarage\n",
    "## Impute GarageYrBlt with YearBuilt\n",
    "\n",
    "def garage_feat(pdf:pd.DataFrame) -> pd.DataFrame:\n",
    "    # hasGarage: 0 or 1\n",
    "    pdf[\"hasGarage\"] = [0 if pd.isnull(x) else 1 for x in pdf[\"GarageYrBlt\"]]\n",
    "\n",
    "    # GarageBlt\n",
    "    pdf[\"GarageBlt\"] = pdf[\"GarageYrBlt\"] - pdf[\"YearBuilt\"] + 1\n",
    "    pdf.loc[pdf[\"GarageYrBlt\"].isna(), \"GarageBlt\"] = 0\n",
    "    pdf = pdf.drop(columns=[\"GarageYrBlt\"])\n",
    "    return(pdf)\n",
    "\n",
    "house_train = garage_feat(house_train.copy())\n",
    "house_test = garage_feat(house_test.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=house_train, x=\"YearBuilt\", y=\"GarageBlt\", hue=\"hasGarage\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing other missing data using KNN and Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "# KNN imputer for numeric values\n",
    "imputer_num = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Simple mode imputer for categoricals\n",
    "# imputer_cat = SimpleImputer(strategy=\"most_frequent\") # dont use as it drops catagorical info, roll your own\n",
    "def mode_imputer(pdf):\n",
    "    modes = pdf.mode().T\n",
    "    for f in pdf.columns:\n",
    "        pdf[f] = pdf[f].fillna(modes.loc[f][0])\n",
    "    return(pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(pdf:pd.DataFrame):\n",
    "    # Columns have changed since we first identified all the types, so re-ID numeric vs categorical features\n",
    "    numeric_cols = pdf.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_cols = [c for c in pdf.columns if c not in numeric_cols]\n",
    "\n",
    "    # Impute missing values separately\n",
    "    pdf_num_imputed = pd.DataFrame(imputer_num.fit_transform(pdf[numeric_cols]), columns=numeric_cols)\n",
    "    pdf_cat_imputed = mode_imputer(pdf[categorical_cols].copy())\n",
    "\n",
    "    # Join the imputed versions back together\n",
    "    pdf_concat = pd.concat([pdf_num_imputed, pdf_cat_imputed], axis=1)\n",
    "    pdf_concat[\"Id\"] = pdf_concat[\"Id\"].astype(int)\n",
    "    return(pdf_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train = imputer(house_train)\n",
    "house_test = imputer(house_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at missing again\n",
    "display(missing_plotter(house_train)[:5])\n",
    "display(missing_plotter(house_test)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Variance Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearZeroVar(pdf, features, freqCut=95/5, uniqueCut=10):\n",
    "    features = list(features)\n",
    "\n",
    "    n_unique = []\n",
    "    freqRatio = []\n",
    "    percentUnique = []\n",
    "    for f in features:\n",
    "        tmp = pdf.groupby(f).size()\n",
    "        tmp = tmp[tmp>0].sort_values(ascending=False).reset_index(drop=True)\n",
    "        n_unique.append(len(tmp))\n",
    "        freqRatio.append(tmp[0]/tmp[1])\n",
    "        percentUnique.append((len(tmp)/len(pdf[f]))*100)\n",
    "\n",
    "    res = pd.DataFrame()\n",
    "    res['feature'] = features\n",
    "    res['freqRatio'] = freqRatio\n",
    "    res['percentUnique'] = percentUnique\n",
    "\n",
    "    res[\"zeroVar\"] = [True if i == 1 else False for i in n_unique]\n",
    "    res[\"nzv\"] = (res['freqRatio'] > freqCut) & (res['percentUnique'] < uniqueCut)\n",
    "\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nzv = nearZeroVar(house_train, house_train.columns, freqCut=99/1, uniqueCut=5)\n",
    "nzv = nzv[nzv[\"nzv\"]]\n",
    "nzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these\n",
    "house_train = house_train.drop(columns=nzv[\"feature\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Feature engineering: Transforming YearRemodAdd\n",
    "- Remodel date (same as construction date if no remodeling or additions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_data = house_train[[\"YearBuilt\", \"YearRemodAdd\"]].copy()\n",
    "plt_data[\"remodel==constr\"] = plt_data[\"YearRemodAdd\"]==plt_data[\"YearBuilt\"]\n",
    "plt_data[\"remodel==constr\"]\n",
    "\n",
    "sns.scatterplot(data=plt_data, x=\"YearBuilt\", y=\"YearRemodAdd\", hue=\"remodel==constr\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new features from YearRemodAdd\n",
    "- it looks like many houses built before 1950 was remodelled in 1950 - unlikely, lets assume that if a house was built before 1950, and remodelled in 1950, in fact it was never remodelled and someone simply used 1950 as a default settign for all those houses.\n",
    "\n",
    "- We will try and capture the information in YearRemodAdd in 2 other variables\n",
    "    - **isRemod**: indicates whether the house is remodelled\n",
    "    - **RemodAdd**: years + 1 after construction that the house was remodelled. \n",
    "        - 0 indicates no remodel, + integer indicates remodelled after years + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = house_train.copy()\n",
    "pdf.loc[pdf[\"YearRemodAdd\"] == 1950, \"YearRemodAdd\"] = pdf.loc[pdf[\"YearRemodAdd\"] == 1950, \"YearBuilt\"]\n",
    "sns.scatterplot(data=pdf, x=\"YearBuilt\", y=\"YearRemodAdd\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remod_feat(pdf:pd.DataFrame) -> pd.DataFrame:\n",
    "    # Correct remodelling date for 1950 remodelled\n",
    "    pdf.loc[pdf[\"YearRemodAdd\"] == 1950, \"YearRemodAdd\"] = pdf.loc[pdf[\"YearRemodAdd\"] == 1950, \"YearBuilt\"]\n",
    "    pdf[\"isRemod\"] = (pdf[\"YearRemodAdd\"]==pdf[\"YearBuilt\"]).astype(int)\n",
    "\n",
    "    pdf[\"RemodAdd\"] = pdf[\"YearRemodAdd\"] - pdf[\"YearBuilt\"]\n",
    "    pdf = pdf.drop(columns=[\"YearRemodAdd\"])\n",
    "    return(pdf)\n",
    "\n",
    "house_train = remod_feat(house_train.copy())\n",
    "house_test = remod_feat(house_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=house_train, x=\"YearBuilt\", y=\"RemodAdd\", hue=\"isRemod\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming SalePrice to log scale\n",
    "Transforms can sometimes help models converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train[\"logSalePrice\"] = np.log(house_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train.to_pickle(Path(\"house_train_preproc.pkl\"))\n",
    "house_test.to_pickle(Path(\"house_test_preproc.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train = pd.read_pickle(Path(\"house_train_preproc.pkl\"))\n",
    "house_test = pd.read_pickle(Path(\"house_test_preproc.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Parameter Tuning\n",
    "We will use Microsofts LightGBM framework to build a regression tree model for our data, and then see if we can improve performance via some hyper parameter tuning.\n",
    "## Prepare the dataset for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID features and target variables\n",
    "features = [c for c in house_train.columns if c not in [\"Id\", \"SalePrice\", \"logSalePrice\"]]\n",
    "target1 = \"SalePrice\"\n",
    "target2 = \"logSalePrice\"\n",
    "\n",
    "# split into train and validation sets\n",
    "X, y = house_train[features], house_train[target1]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a vanilla model to set a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quieten some LGBM warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# SKLearn API\n",
    "params = { \n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'poisson',\n",
    "    'metric': 'rmse',\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "evals={}\n",
    "model = lgb.LGBMRegressor(**params)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    verbose=-1,\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals), \n",
    "        lgb.early_stopping(100),\n",
    "        lgb.log_evaluation(0)\n",
    "    ], \n",
    ")\n",
    "\n",
    "lgb.plot_metric(evals);\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "rmse_vanilla = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"\\nRoot Mean Squared Error:\", rmse_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs Observed\n",
    "plt.scatter(y_valid, y_pred, alpha=.3, linewidth=0)\n",
    "plt.plot([0,max(y_valid)], [0, max(y_valid)], color=\"red\")\n",
    "plt.xlabel(\"Observed\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Predicted vs Observed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "Lets find out whether we can perhaps ignore some of our features, building simpler better models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_imp_plotter(m, topn=0):\n",
    "    feature_imp = pd.DataFrame({'importance':m.feature_importances_}, index=m.feature_name_)\\\n",
    "        .sort_values(\"importance\")\n",
    "    if topn > 0:\n",
    "        feature_imp = feature_imp.tail(topn)\n",
    "        height = math.ceil(topn/5)\n",
    "    else:\n",
    "        feature_imp = feature_imp[feature_imp[\"importance\"] > 0]\n",
    "        height = int(len(feature_imp)/5)\n",
    "    feature_imp = feature_imp[feature_imp[\"importance\"] > 0]\n",
    "    tot = feature_imp[\"importance\"].sum()\n",
    "    feature_imp[\"cumulative_importance_percent\"] = ((feature_imp['importance'][::-1]/tot)*100).cumsum()\n",
    "    feature_imp.plot.barh(subplots=True, sharex=False, sharey=True, layout=(1,2), figsize=(10,height))\n",
    "    return(feature_imp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = feat_imp_plotter(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Test model performance with fewer metrics\n",
    "Lets get a general idea what happens if we drop some less important features... This can be useful when you have many thousands of features, and need a simpler faster model.\n",
    "\n",
    "Generally it's at the expense of some score-performance, but that is ok sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small helper function to quickly train and test the impact of feature changes on model performance\n",
    "def model_feat_test(feature_imp, cutoff):\n",
    "    # ID features and target variables\n",
    "    features = list(feature_imp.loc[feature_imp[\"cumulative_importance_percent\"]<=cutoff].index)\n",
    "    target = \"SalePrice\"\n",
    "\n",
    "    # split into train and validation sets\n",
    "    X, y = house_train[features], house_train[target]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # SKLearn API\n",
    "    params = { \n",
    "        'boosting': 'gbdt',\n",
    "        'objective': 'poisson',\n",
    "        'metric': 'rmse',\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        verbose=-1,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(100),\n",
    "            lgb.log_evaluation(0)\n",
    "        ], \n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    \n",
    "    return(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(feature_imp.tail())\n",
    "\n",
    "cutoffs = [85, 90, 95, 100]\n",
    "results = pd.DataFrame({'rmse':np.nan}, index=cutoffs)\n",
    "# results.loc[85][\"rmse\"] = 5\n",
    "# results\n",
    "for cutoff in cutoffs:\n",
    "    results.loc[cutoff][\"rmse\"] = model_feat_test(feature_imp, cutoff)\n",
    "    # results.append(model_feat_test(feature_imp, cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)\n",
    "rmse_feat = results['rmse'].min()\n",
    "print(f\"To beat: {rmse_vanilla}\")\n",
    "print(f\"best: {rmse_feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming off features which contribute to our model has an impact on score as expected, but trimming off zero contributing features actually improved the score a bit, so lets do that.\n",
    "\n",
    "### Retain only contributing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(feature_imp.index)\n",
    "target1 = \"SalePrice\"\n",
    "target2 = \"logSalePrice\"\n",
    "\n",
    "# Split the features from the target variable\n",
    "X, y = house_train[features], house_train[target1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Hyperparameter tuning and Cross validation\n",
    "Hyperparameter tuning: testing various combinations of model parameters, looking for optima\n",
    "\n",
    "Cross validation: measuring model parameter performance across subsets of your data to measure performance and importantly stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Optuna to manage out hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build OpTunas objective function\n",
    "def objective(trial, X, y):\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "\n",
    "    #static parameters\n",
    "    param_static = { \n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'poisson',\n",
    "        'metric': 'rmse',\n",
    "        'verbose': -1,\n",
    "        'n_estimators': 10000\n",
    "    }\n",
    "    \n",
    "    # the parameter grid from where unique parameters will be drawn\n",
    "    param_grid = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.3, step=0.001),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 60, step=1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 50)\n",
    "    }\n",
    "\n",
    "    # set up cross validation\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # for storing scores from the K-Folds\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(\n",
    "            **param_static, \n",
    "            **param_grid)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        eval_metric=\"rmse\",\n",
    "        categorical_feature=\"auto\",\n",
    "            verbose=-1,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(100, verbose=0),\n",
    "                lgb.log_evaluation(0)\n",
    "            ]\n",
    "        )\n",
    "        y_pred = model.predict(X_test)\n",
    "        cv_scores[idx] = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "    # return(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress optuna training logs\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "# Create an OpTuna study\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n",
    "\n",
    "# Call the Optuna Objective function, and begine some simple hyperparameter tuning\n",
    "func = lambda trial: objective(trial, X, y)\n",
    "study.optimize(func, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optuna** has a few useful canned plots that can show us interesting info about interactions between our hyperparameters.\n",
    "\n",
    "https://optuna.readthedocs.io/en/stable/reference/visualization/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameter relations as scatter plots with colors indicating ranks of target value.\n",
    "fig = optuna.visualization.plot_rank(study, target_name=\"rmse\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the final model using optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_static = { \n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'poisson',\n",
    "    'metric': 'rmse',\n",
    "    'verbose': -1,\n",
    "    'n_estimators': 10000\n",
    "}\n",
    "\n",
    "evals={}\n",
    "model = lgb.LGBMRegressor(\n",
    "    **param_static, \n",
    "    **study.best_params)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=-1,\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals), \n",
    "        lgb.early_stopping(100),\n",
    "        lgb.log_evaluation(0)\n",
    "    ], \n",
    ")\n",
    "\n",
    "lgb.plot_metric(evals);\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "rmse_final = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"\\nTo beat: {rmse_feat}\")\n",
    "print(\"Root Mean Squared Error:\", rmse_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick hyperparameter tuning has improves out RMSE score on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
